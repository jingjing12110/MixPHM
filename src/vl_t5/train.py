# @File :train.py# @Time :2022/6/5# @Desc :import osimport timeimport shutilimport randomimport datetimeimport numpy as npfrom tqdm import tqdmimport torchimport torch.backends.cudnn as cudnnimport torch.distributed as distfrom colorama import init, Fore, Back, Stylefrom vl_t5.utils import LossMeter, EarlyStoppingV2from vl_t5 import dist_utilsfrom vl_t5 import utilsfrom vl_t5.param import parse_argsfrom vl_t5.vqa_model import VLT5VQAfrom vl_t5.trainer_base import TrainerBasefrom tools import write_txtclass Trainer(TrainerBase):    def __init__(self, args, train=True):        super().__init__(args)        self.verbose = True        model_kwargs = {}        # ### 设置adapter参数 ###        config = self.create_config()        self.model = self.create_model(VLT5VQA, config, **model_kwargs)        self.tokenizer = self.create_tokenizer()        self.model.resize_token_embeddings(self.tokenizer.vocab_size)        self.model.tokenizer = self.tokenizer        # Load Checkpoint        print(f'Model Launching:')        self.start_epoch = None        if args.load is not None:            ckpt_path = args.load + '.pth'            self.load_checkpoint(ckpt_path)        if self.args.from_scratch:            self.init_weights()        # GPU Options        device = torch.device(args.device)        self.model = self.model.to(device)        trainable_params = []        fixed_params = []        if args.apply_lora:            trainable_params.append('lora')        if args.apply_adapter:            trainable_params.append('adapter')        if args.apply_expert_soup:            trainable_params.append('ExpertSoup')            fixed_params.append('expert_score_weight')        if args.apply_bitfit:            trainable_params.append('bias')        if args.apply_moe:            trainable_params.append('AdaMoE')        if args.apply_adapter_moe:            trainable_params.append('ada_moe')            fixed_params.append('expert_score_weight')        if args.apply_compacter:            fixed_params.append('expert_score_weight')            if args.learn_phm and config.hypercomplex_adapter:                trainable_params.append("phm_rule")            trainable_params.append('phm_adapter')            if args.use_adapter_cross_attn:                trainable_params.append('cross_attn_phm_adapter')            if args.use_adapter_self_attn:                trainable_params.append('self_attn_phm_adapter')        if args.apply_phm_moe:            fixed_params.append('expert_score_weight')            if args.learn_phm and config.hypercomplex_adapter:                trainable_params.append("phm_rule")            trainable_params.append('phm_adapter_moe')            if args.hypercomplex_nonlinearity == "lora":                fixed_params.append('W_lora_fix')        if len(trainable_params) > 0:            for name, param in self.model.named_parameters():                param.requires_grad = False                for trainable_param in trainable_params:                    if trainable_param in name:                        param.requires_grad = True                        print(f"{name} is trainable...")                        break                if len(fixed_params) > 0:                    for fixed_param in fixed_params:                        if fixed_param in name:                            param.requires_grad = False                            print(f"{name} is Fixed...")                            break        self.print_trainable_params_percentage(self.model)        if args.distributed:            self.model = torch.nn.parallel.DistributedDataParallel(                self.model,                device_ids=[args.gpu],                find_unused_parameters=False            )        print(f'Building train loader')        if args.data_name == "vqav2":            from vl_t5.fs_vqa_data import get_k_shot_loader, get_loader            args.num_tasks = utils.get_world_size()            args.global_rank = utils.get_rank()            self.train_loader = get_k_shot_loader(                args=args,                split=args.train,                mode='train',                distributed=args.distributed,                shuffle=True,                batch_size=args.batch_size,                workers=args.num_workers,            )            self.val_loader = get_k_shot_loader(                args=args,                split=args.valid,                mode='val',                distributed=args.distributed,                shuffle=False,                batch_size=args.valid_batch_size,                workers=args.num_workers,            )            self.test_loader = get_loader(                args,                split=args.test,                mode='val',                distributed=args.distributed,                batch_size=args.valid_batch_size,                workers=args.num_workers,                topk=args.valid_topk,            )        elif args.data_name == 'okvqa':            from vl_t5.ok_data import get_loader            args.num_tasks = utils.get_world_size()            args.global_rank = utils.get_rank()            self.train_loader = get_loader(                args=args,                split=args.train,                mode='train',                distributed=args.distributed,                shuffle=True,                batch_size=args.batch_size,                workers=args.num_workers,            )            self.val_loader = get_loader(                args=args,                split=args.valid,                mode='val',                distributed=args.distributed,                shuffle=False,                batch_size=args.valid_batch_size,                workers=args.num_workers,            )            self.test_loader = get_loader(                args,                split=args.test,                mode='val',                distributed=args.distributed,                shuffle=False,                batch_size=args.valid_batch_size,                workers=args.num_workers,            )        elif args.data_name == "gqa":            from vl_t5.gqa_data import get_loader            args.num_tasks = utils.get_world_size()            args.global_rank = utils.get_rank()            self.train_loader = get_loader(                args=args,                split=args.train,                mode='train',                shuffle=True,                distributed=args.distributed,                batch_size=args.batch_size,                workers=args.num_workers,            )            self.val_loader = get_loader(                args=args,                split=args.valid,                mode='val',                shuffle=False,                distributed=args.distributed,                batch_size=args.valid_batch_size,                workers=args.num_workers,            )            self.test_loader = get_loader(                args,                split=args.test,                mode='val',                shuffle=False,                distributed=args.distributed,                batch_size=args.valid_batch_size,                workers=args.num_workers,            )        # Optimizer        if train:            self.optim, self.lr_scheduler = \                self.create_optimizer_and_scheduler()        # early stopping        self.es_metric_acc = 0.        self.es_stop_counter = 0        self.es_patience = args.es_patience        self.early_stopping = EarlyStoppingV2(            patience=args.es_patience,            delta=1e-2,            less_is_better=False        )        self.es_total_score = 0    def train(self):        loss_meter = LossMeter()        best_valid = 0.        best_valid_epoch = 0        global_step = 0        if self.args.distributed:            dist.barrier()        # iter_times = []        # start_time = time.time()        for epoch in range(self.args.epochs):            if args.distributed:                self.train_loader.sampler.set_epoch(epoch)            if self.start_epoch is not None:                epoch += self.start_epoch            self.model.train()            epoch_results = {'loss': 0.}            pbar = tqdm(total=len(self.train_loader), ncols=160)            for step_i, batch in enumerate(self.train_loader):                if self.args.distributed:                    results = self.model.module.train_step(batch)                else:                    results = self.model.train_step(batch)                loss = results['loss']                loss.backward()                loss = loss.detach()                # Update Parameters                torch.nn.utils.clip_grad_norm_(                    self.model.parameters(), self.args.clip_grad_norm)                self.optim.step()                if self.lr_scheduler:                    self.lr_scheduler.step()                for param in self.model.parameters():                    param.grad = None                global_step += 1                for k, v in results.items():                    if k in epoch_results:                        epoch_results[k] += v.item()                lr = self.lr_scheduler.get_last_lr()[0]                loss_meter.update(loss.item())                desc_str = f'Epoch {epoch} | LR {lr:.2e}'                desc_str += f' | Loss {loss_meter.val:.2f}'                for loss_name, loss_value in results.items():                    if loss_name != "loss":                        desc_str += f"| {loss_name} {loss_value:.2f} "                pbar.set_description(desc_str)                pbar.update(1)                if self.args.distributed:                    dist.barrier()            pbar.close()            if ((epoch + 1) % self.args.val_interval == 0) or (                    (epoch + 1) == self.args.epochs):                # Validation                val_acc = self.evaluate(self.val_loader)                val_acc = float(f"{val_acc * 100:.2f}")                log_str = ''                log_str += \                    f"\nEpoch{epoch}: Train_loss: " \                    f"{epoch_results['loss'] / len(self.train_loader):.5f}"                log_str += f"\nEpoch{epoch}: val_acc: {val_acc}"                if val_acc >= best_valid:                    best_valid = val_acc                    best_valid_epoch = epoch                    self.save("BEST")                log_str += f"\nbest epoch: {best_valid_epoch}" \                           f"\nbest_val_acc: {best_valid}\n"                with open(self.args.output + "/log.log", 'a') as f:                    f.write(log_str)                    f.flush()                print(log_str)                self.es_total_score += val_acc                if self.es_total_score > 0.:                    stop = self.early_stopping.step(val_acc)                    if stop:                        print(                            f'Early stopping! Best validation acc: '                            f'{self.early_stopping.get_best_score()}')                        break            if self.args.distributed:                dist.barrier()        if self.args.data_name == "gqa":            evaluator = self.test_loader.evaluator            # Test for Last            quesid2ans = self.predict(self.test_loader)            test_acc_last = evaluator.evaluate(quesid2ans) * 100            # Test Set            best_path = os.path.join(self.args.output, 'BEST')            self.load(best_path)            quesid2ans = self.predict(self.test_loader)            test_acc_best = evaluator.evaluate(quesid2ans) * 100        else:            evaluator = self.test_loader.evaluator            # Test for Last            quesid2ans = self.predict(self.test_loader)            acc_dict_all_last = evaluator.evaluate_raw(quesid2ans)            test_acc_last = acc_dict_all_last['overall']            # Test Set            best_path = os.path.join(self.args.output, 'BEST')            self.load(best_path)            quesid2ans = self.predict(self.test_loader)            acc_dict_all_best = evaluator.evaluate_raw(quesid2ans)            test_acc_best = acc_dict_all_best["overall"]        test_log_str = ''        test_log_str += f"\nSeed: {args.seed}; \n" \                        f"Test acc of BEST: {test_acc_best:.2f} \n" \                        f"Test acc of LAST: {test_acc_last:.2f}"        print(test_log_str)        with open(self.args.output + "/acc_all.txt", 'a+') as f:            f.write(test_log_str)            f.flush()        if self.args.distributed:            dist.barrier()        return test_acc_last, test_acc_best    def compute_evaluation_loss(self, loader):        self.model.eval()        evaluation_loss = 0        pbar = tqdm(total=len(loader), ncols=80, ascii=True, desc="Predict")        with torch.no_grad():            for i, batch in enumerate(loader):                if self.args.distributed:                    results = self.model.module.train_step(batch)                else:                    results = self.model.train_step(batch)                evaluation_loss += results['loss'].item()                if self.verbose:                    pbar.update(1)        pbar.close()        # if self.args.distributed:        #     dist.barrier()        return evaluation_loss / len(loader)    def predict(self, loader, dump_path=None):        self.model.eval()        with torch.no_grad():            quesid2ans = {}            pbar = tqdm(total=len(loader), ncols=80, ascii=True, desc="Predict")            for i, batch in enumerate(loader):                if self.args.distributed:                    results = self.model.module.test_step(batch)                else:                    results = self.model.test_step(batch)                pred_ans = results['pred_ans']                ques_ids = batch['question_ids']                for qid, ans in zip(ques_ids, pred_ans):                    quesid2ans[qid] = ans                if self.verbose:                    pbar.update(1)            pbar.close()        if self.args.distributed:            dist.barrier()        qid2ans_list = dist_utils.all_gather(quesid2ans)        if self.verbose:            quesid2ans = {}            for qid2ans in qid2ans_list:                for k, v in qid2ans.items():                    quesid2ans[k] = v            if dump_path is not None:                evaluator = loader.evaluator                evaluator.dump_result(quesid2ans, dump_path)        return quesid2ans    def evaluate(self, loader, dump_path=None):        quesid2ans = self.predict(loader, dump_path)        if self.verbose:            evaluator = loader.evaluator            # acc_dict = evaluator.evaluate_raw(quesid2ans)            overall_score = evaluator.evaluate(quesid2ans)            # acc_dict['topk_score'] = topk_score            # return acc_dict            return overall_scoredef main(args):    utils.init_distributed_mode(args)    cudnn.benchmark = True    torch.set_num_threads(args.num_workers)    init(autoreset=True)    acc_seed_list_last = []    acc_seed_list_best = []    for s in args.seeds.split(','):        args.seed = int(s)        args.dataseed = args.seed        print(80 * '=')        print(Style.NORMAL + Back.LIGHTYELLOW_EX + Fore.RED + f"seed: {s}")        print(80 * '=')        # fix the seed for reproducibility        torch.manual_seed(args.seed)        np.random.seed(args.seed)        random.seed(args.seed)        start_time = time.time()        # training        trainer = Trainer(args, train=True)        test_acc_last, test_acc_best = trainer.train()        total_time = time.time() - start_time        total_time_str = str(datetime.timedelta(seconds=int(total_time)))        print('Training time {}'.format(total_time_str))        acc_seed_list_last.append(test_acc_last)        acc_seed_list_best.append(test_acc_best)    acc_seed_last = torch.tensor(acc_seed_list_last)    acc_seed_best = torch.tensor(acc_seed_list_best)    acc_seed_last_ms = f"{acc_seed_last.mean():.2f}+-{acc_seed_last.std():.2f}"    print(acc_seed_last)    print(f"LAST mean+-std: {acc_seed_last_ms}")    acc_seed_best_ms = f"{acc_seed_best.mean():.2f}+-{acc_seed_best.std():.2f}"    print(acc_seed_best)    print(f"BEST mean+-std: {acc_seed_best_ms}")    write_txt(f"{args.output}/test_acc.txt",              f"{acc_seed_list_last}\n"              f"LAST mean+-std: {acc_seed_last_ms}\n"              f"{acc_seed_list_best}\n"              f"BEST mean+-std: {acc_seed_best_ms}\n"              )if __name__ == "__main__":    args = parse_args()    args.run_name = f"{datetime.datetime.now().strftime('%b%d_%H-%M')}"    print(args)    main(args)